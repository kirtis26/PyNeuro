{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyNeuro\n",
    "## Модель машинного обучения  - НЕЙРОННАЯ СЕТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from numpy import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Класс Нейронная сеть\n",
    "    Обучение сети проходит методом обратного распространения ошибки\n",
    "    layers - объект типа list: например, layers = [4, 20, 10, 5, 1]\n",
    "             4 нейрона на слое входных данных (input layers);\n",
    "             3 скрытых слоя сети NN (hidden layers), содержащих 20, 10 и 5 нейронов, соотвественно;\n",
    "             1 нейрон в выходном слое (output layers).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers, weights=None):\n",
    "        self.layers = layers\n",
    "        self.weights = weights\n",
    "        self.activations_value = None\n",
    "        self.summary_arg = None\n",
    "        self.n_layers = len(layers)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"NeuralNetwork:\\n - input layer: {self.layers[0]} neurons;\\n - output layer: {self.layers[-1]} neurons;\\n - hidden layers: {len(self.layers[1:-1])}\"\n",
    "    \n",
    "    def function_activation(self, arg):\n",
    "        \"\"\"\n",
    "        Ф-ция активации - бинарная сигмоидальная функция с областью значений (0, 1)\n",
    "        \"\"\"\n",
    "        fx = 1 / (1 + np.exp(-arg))\n",
    "        if fx == 1:\n",
    "            return 1 - 1e-9\n",
    "        elif fx == 0:\n",
    "            return 0 + 1e-9\n",
    "        else:\n",
    "            return fx\n",
    "    \n",
    "    def derivative_activation(self, arg):\n",
    "        return (1 / (1 + np.exp(-arg))) * (1 - (1 / (1 + np.exp(-arg))))\n",
    "    \n",
    "    def create(self):\n",
    "        \"\"\"\n",
    "        Ф-ция инициилизации нейронной сети. С помощью генератора списка создает матрицы \n",
    "        весов связей weights между нейронами каждого слоя со случайными числами от -1 до 1.\n",
    "        !ПРИМЕЧАНИЕ!: начальная матрица весов W[0] = 0.\n",
    "        \"\"\"\n",
    "        self.weights = [np.mat(rd.uniform(-1, 1, (self.layers[i], 1+self.layers[i-1])))\n",
    "                     if i!=0 else 0 for i in range(self.n_layers)]\n",
    "        \n",
    "    def run(self, input_data):\n",
    "        \"\"\"\n",
    "        Ф-ция вычисления матрицы выходных сигналов сети. \n",
    "        input_data - входные данные (может быть несколько сразу)\n",
    "        !ПРИМЕЧАНИЕ!: Значения активационной функции для входного слоя равны самим значениям\n",
    "        \"\"\"\n",
    "        count_sample = len(input_data)\n",
    "        self.activations_value = [deepcopy(input_data)]\n",
    "        self.summary_arg = [0]   \n",
    "        fa = np.vectorize(self.function_activation)\n",
    "        \n",
    "        for i in range(1, self.n_layers):\n",
    "            self.activations_value[i-1] = np.c_[np.ones(count_sample), self.activations_value[i-1]]\n",
    "            self.summary_arg.append(self.activations_value[i-1] * self.weights[i].T)\n",
    "            self.activations_value.append(fa(self.summary_arg[i]))\n",
    "            \n",
    "        out_signal = self.activations_value[-1]\n",
    "        return out_signal\n",
    "            \n",
    "    def backpropagation(self, X, Y_expect, lambd):\n",
    "        \"\"\"\n",
    "        Метод обратного распространения ошибки\n",
    "        X - входные значения\n",
    "        Y_expect - ожидаемые выходные значения сети \n",
    "        \"\"\"\n",
    "        count_layers = self.n_layers\n",
    "        count_sample = len(X)\n",
    "        delta_W = [0] * count_layers\n",
    "        Y_expect = np.matrix(Y_expect)\n",
    "        Y = deepcopy(self.run(X))\n",
    "        W = deepcopy(self.weights)\n",
    "        Z = deepcopy(self.summary_arg)\n",
    "        A = deepcopy(self.activations_value)\n",
    "        foo_der = np.vectorize(self.derivative_activation)\n",
    "        \n",
    "        for n in range(0, count_sample):\n",
    "            delta = [0] * (count_layers + 1)\n",
    "            delta[-1] = (Y[n] - Y_expect[n]).T\n",
    "            for i in range(count_layers - 1, 0, -1):\n",
    "                if i > 1:\n",
    "                    z = Z[i-1][n]\n",
    "                    z = np.c_[[[1]], z]\n",
    "                    delta[i] = np.multiply(W[i].T * delta[i + 1], foo_der(z).T)\n",
    "                    delta[i] = delta[i][1:]\n",
    "                delta_W[i] += delta[i + 1] * A[i - 1][n]\n",
    "\n",
    "        for i in range(1, len(delta_W)):\n",
    "            delta_W[i] = delta_W[i] / count_layers\n",
    "            delta_W[i][:, 1:] = delta_W[i][:, 1:] + W[i][:, 1:] * (lambd / count_layers)\n",
    "            \n",
    "        return delta_W\n",
    "    \n",
    "    def get_error(self, X, Y, lambd):\n",
    "        \"\"\"\n",
    "        Ф-ция вычисления ошибки выходного сигнала нейронной сети с регуляризацией\n",
    "        lambd - коэффициент регуляризации\n",
    "        X - входные данные\n",
    "        Y - выходные значения \n",
    "        \"\"\"\n",
    "        count_sample = len(X)\n",
    "        Y = np.matrix(deepcopy(Y))\n",
    "        W = deepcopy(self.weights)\n",
    "        H = self.run(X)\n",
    "        \n",
    "        cost = (-1 * Y.T * np.log(H) - (1 - Y.T) * np.log(1 - H)).sum(axis=0).sum(axis=1)\n",
    "        regul = 0\n",
    "        \n",
    "        for i in range(1, len(W)):\n",
    "            W[i] = np.delete(W[i], 0, axis=1)\n",
    "            W[i] = np.power(W[i], 2)\n",
    "            regul += W[i].sum(axis=0).sum(axis=1)\n",
    "            \n",
    "        return cost / count_sample + (lambd / (2 * count_sample)) * regul\n",
    "\n",
    "    def training(self, xTrain, yTrain, xTest, yTest, alpha=0.2, lambd=0.3, maxiter=1000):\n",
    "        \"\"\"\n",
    "        Ф-ция обучения нейронной сети - подбирает матрицу весов связей на основе обучающей выборки\n",
    "        alpha - отвечает за скорость обучения (насколько сильно изменяется матрица весов в каждой итерации)\n",
    "        \"\"\"\n",
    "        eps, mi = 1, 0\n",
    "        \n",
    "        while eps > 0 and mi < maxiter:\n",
    "            eps = self.get_error(xTrain, yTrain, lambd)\n",
    "            eps_test = self.get_error(xTest, yTest, lambd)\n",
    "            delta = self.backpropagation(xTrain, yTrain, lambd)\n",
    "            self.weights = [self.weights[i] - alpha * delta[i] for i in range(len(self.weights))]\n",
    "            mi += 1\n",
    "        \n",
    "        print(f'iter: {mi}, error train: {eps[0, 0]}, error test: {eps_test[0, 0]}')\n",
    "        print(f'X_test:\\n{self.run(xTest)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример обучения нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [4, 16, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork:\n",
       " - input layer: 4 neurons;\n",
       " - output layer: 1 neurons;\n",
       " - hidden layers: 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание объекта класса Нейронная сеть\n",
    "NN = NeuralNetwork(layers)\n",
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание нейронной сети (инициилизация случаных весовых коэф-ов связей)\n",
    "NN.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучающая выборка: если последовательность возрастающая то 1, иначе - 0\n",
    "X_train = [[1, 2, 3, 4],\n",
    "          [5, 6, 7, 8],\n",
    "          [9, 10, 11, 12],\n",
    "          [1, 3, 5, 7],\n",
    "          [2, 4, 6, 8],\n",
    "          [1.1, 1.2, 1.3, 1.4],\n",
    "          [1.5, 1.6, 1.7, 1.8],\n",
    "          [1.9, 2.0, 2.1, 2.2],\n",
    "          [2.3, 2.4, 2.5, 2.6],\n",
    "          [2.7, 2.8, 2.9, 3.0],\n",
    "          [3.15, 3.33, 3.54, 3.88],\n",
    "          [4.5, 5.5, 6.5, 7.5],\n",
    "          [1.9, 2.9, 3.9, 4.9],\n",
    "          [5.55, 6.66, 7.77, 8.88],\n",
    "          [4.6, 5.8, 6.0, 8.1],\n",
    "          [4, 3, 2, 1],\n",
    "          [8, 7, 6, 5],\n",
    "          [12, 11, 10, 9],\n",
    "          [7, 5, 3, 1],\n",
    "          [8, 6, 4, 2],\n",
    "          [1.45, 1.34, 1.23, 1.12],\n",
    "          [1.89, 1.78, 1.66, 1.51],\n",
    "          [2.24, 2.18, 2.05, 1.9],\n",
    "          [2.64, 2.50, 2.48, 2.37],\n",
    "          [3.1, 2.95, 2.82, 2.71],\n",
    "          [3.94, 3.75, 3.59, 3.45],\n",
    "          [8.59, 7.58, 6.57, 5.56],\n",
    "          [4.98, 3.9, 2.98, 1.9],\n",
    "          [8.86, 7.76, 6.66, 5.56],\n",
    "          [9.5, 5.67, 4.7, 1.46],]\n",
    "Y_train = [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1],\n",
    "          [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= [[1.25, 2.25, 3.25, 4.25],\n",
    "        [2.28, 3.38, 4.38, 5.38],\n",
    "        [5.55,6.66, 7.77, 8.88],\n",
    "        [1.11, 2.22, 3.33, 4.44],\n",
    "        [3.7, 6.8, 7.9, 8.0],\n",
    "        [6.94, 5.81, 4.38, 1.2],\n",
    "        [6.0, 5.0, 4.4, 3.5],\n",
    "        [7.26, 6.69, 4.3, 4.29],\n",
    "        [2.25, 2.20, 2.15, 2.10],\n",
    "        [9, 8, 7, 6]]\n",
    "Y_test = [[1], [1], [1], [1], [1],\n",
    "         [0], [0], [0], [0], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000, error train: 0.5017070303321093, error test: 0.7274777513460905\n",
      "X_test:\n",
      "[[0.94999539]\n",
      " [0.92942222]\n",
      " [0.90162292]\n",
      " [0.9586506 ]\n",
      " [0.92224177]\n",
      " [0.05440955]\n",
      " [0.20053599]\n",
      " [0.15850985]\n",
      " [0.51268438]\n",
      " [0.23574216]]\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "# Обучение созданной сети\n",
    "%time NN.training(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " matrix([[-1.07288012, -0.65115024, -0.32789222, -0.02933839,  0.31581379],\n",
       "         [-0.87818738, -1.17040836, -0.40883909,  0.28795051,  1.11280862],\n",
       "         [-0.64134198,  0.41555115,  0.15447006, -0.07842516, -0.35469024],\n",
       "         [-0.76487392,  0.71306418,  0.09446931, -0.45780955, -1.12057501],\n",
       "         [-0.93847346,  0.64089602, -0.02762556, -0.63035298, -1.34642739],\n",
       "         [-0.2254992 , -0.87507196, -0.2731599 ,  0.2829147 ,  0.93258997],\n",
       "         [-0.0146954 , -1.76676971, -0.86430284, -0.0253794 ,  0.94739395],\n",
       "         [-0.54664523, -1.06201457, -0.46092684,  0.09512797,  0.74091063],\n",
       "         [-0.59112161, -0.45256404, -0.23066318, -0.02437   ,  0.21250876],\n",
       "         [-1.18215989, -0.35250844, -0.17459201, -0.01017601,  0.17929556],\n",
       "         [-0.11624933,  1.06188775,  0.19473954, -0.59404796, -1.5394081 ],\n",
       "         [-0.03120705,  1.11531237,  0.36669637, -0.31450263, -1.12251214],\n",
       "         [-0.93765201, -0.7284769 , -0.19676482,  0.29101825,  0.86519224],\n",
       "         [-0.42885052, -0.48267998, -0.2550925 , -0.04371616,  0.19920937],\n",
       "         [-0.47011118, -0.5125325 , -0.21153848,  0.06703908,  0.3901741 ],\n",
       "         [-0.55815166,  0.69688868,  0.136235  , -0.37132966, -0.9736638 ]]),\n",
       " matrix([[ 0.05995366,  0.17080676,  0.95211047, -0.40714638, -0.43101909,\n",
       "          -0.55693944,  0.65294251,  0.75686689,  0.32121413,  0.18804902,\n",
       "           0.16021405, -0.79656238, -0.90578361,  0.66795104,  0.19151728,\n",
       "           0.28603311, -0.41989483]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Матрица весов после обучения нейронной сети\n",
    "Weights = NN.weights\n",
    "Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.94666486]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка (экзамен) нейронной сети\n",
    "NN.run([[1.25, 2.2, 3.15, 4.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
